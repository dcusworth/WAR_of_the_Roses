{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from competition_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get wiki for all bachelor seasons\n",
    "allseasons = requests.get(\"https://en.wikipedia.org/wiki/The_Bachelor_(U.S._TV_series)#Seasons\")\n",
    "soup = BeautifulSoup(allseasons.text, \"html.parser\") #make soup element\n",
    "\n",
    "#get the table cell that has links to each episode\n",
    "seasons = soup.find(\"table\", attrs={\"class\":\"navbox\"}).find(\"td\", attrs={\"class\":\"navbox-list navbox-odd hlist\"})\n",
    "seasons = seasons.find(\"div\", attrs={\"style\":\"padding:0em 0.25em\"}).find(\"ul\")\n",
    "\n",
    "urls = []                           #list of links to season-specific page\n",
    "seasonNums = []                     #list of seasons w/ wiki pages (no seasons 1-4 or 6-8)\n",
    "seasonNum = 1                       #season number\n",
    "for item in seasons.find_all(\"li\"): #for each item in list of seasons\n",
    "    if (seasonNum == 20):           #don't include season 20, b/c no contestants listed yet\n",
    "        break\n",
    "    season = item.find(\"a\")         #get url tag\n",
    "    if season is not None:          #if has url link, get url text\n",
    "        urls.append(\"\\\"https://en.wikipedia.org\" + season.get(\"href\") + \"\\\"\")\n",
    "        seasonNums.append(seasonNum) #add season number to list \n",
    "    seasonNum += 1\n",
    "    \n",
    "wikiPageText = []                   #init list of wiki site text, for all seasons\n",
    "for url in urls:\n",
    "    site = requests.get(url[1:-1])  #get web-site for that url\n",
    "    soup = BeautifulSoup(site.text, \"html.parser\") #make BS element\n",
    "    wikiPageText.append(soup)       #add web-site text to list\n",
    "\n",
    "wikiPages = dict(zip(seasonNums, wikiPageText)) #key=season, val=Soup Elem(wiki page text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each season in wiki, make list of dictionaries - one dictionary for each contestant.\n",
    "# Also, make a list of dictionaries of all contestants for all seasons.\n",
    "#\n",
    "# list name       = listAllDicts  #a list of all dicts for all contestants and bachelors, all seasons\n",
    "#\n",
    "# dictionary name = seasonsDict\n",
    "#             key = season number\n",
    "#           value = list of dictionaries for that season (one for each contestant)\n",
    "#             \n",
    "# dictionary name = contestantDict\n",
    "#            keys = name, age, hometown, occupation, elimination, season\n",
    "#          values = associated values to fields, as scraped from wiki\n",
    "#\n",
    "# To test contestant dictionaries:\n",
    "#         print seasonsDict[season][contestant][fieldname]\n",
    "#    eg:  print seasonsDict[9][10]['name']  -- get name for season 9, contestant 10\n",
    "#\n",
    "# Note: Wiki does not have pages dedicated to Seasons 1-4, or 6-8. I added 2, 4, 6, and 8\n",
    "# below, from other sources. Contestants for episode 20 are not added, because they are\n",
    "# not public yet.\n",
    "#\n",
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "seasonsDict = dict()                #key = season num, val=list of contestant dictionaries\n",
    "allContestants = dict()             #keys = name/age/etc, values = associated data\n",
    "listAllDicts = []                   #list of dicts for all cont. and bach. for ALL seasons\n",
    "\n",
    "for sn in seasonNums:\n",
    "    seasonPage = wikiPages[sn]      #get BS element for this season\n",
    "    seasonPage = seasonPage.find(\"div\", attrs={\"id\":\"content\"}).find(\"div\", attrs={\"id\":\"bodyContent\"})\n",
    "    seasonPage = seasonPage.find(\"div\", attrs={\"id\":\"mw-content-text\"})\n",
    "    seasonPage = seasonPage.find(\"table\", attrs={\"class\":\"wikitable sortable\"})\n",
    "    \n",
    "    listOfContestantDicts = []          #list of dicts for each contestant\n",
    "    \n",
    "    numtr = 0                           #num rows (one per contestant)\n",
    "    for tr in seasonPage.find_all(\"tr\"):#for each contestant listed,\n",
    "        if (numtr == 0):                #skip first row (column headers)\n",
    "            numtr += 1\n",
    "            continue\n",
    "\n",
    "        contestantDict = dict()         #init new dict for contestant\n",
    "        numtd = 0                       #column number\n",
    "        for td in tr.find_all(\"td\"):    #for each column of data,\n",
    "            \n",
    "            #NAME\n",
    "            if (numtd == 0):\n",
    "                name = str(td.contents)\n",
    "                if (\"<b>\" in name):\n",
    "                    td.find(\"b\")\n",
    "                    name = str(td.contents)[4:-5]\n",
    "                if ((\"[u'\" in name) or (\"[u\\\"\" in name)):   #if \"[u'name']\",\n",
    "                    name = name.encode('utf8')[3:-2]    #format to get 'name'\n",
    "                if (\"<span class\" in name):\n",
    "                    td.find(\"span\", attrs={\"class\":\"nowrap\"})\n",
    "                    tag = \"<span class='nowrap'>\"       #start tag before name\n",
    "                    name = str(td.contents)[len(tag)+1:]#cut out start tag\n",
    "                    end = name.index(\"<\")               #get start point of end tag\n",
    "                    name = name[:end]                   #cut out end tag\n",
    "                    trashTag = \"style=\\\"display:none;\\\">\" #weird tag to cut from a name\n",
    "                    if (trashTag in name):\n",
    "                        name = name[(len(trashTag)+1):-1] \n",
    "                if (\"<sup\" in name):                    #if name has \"name', <sup ...\",\n",
    "                    end2 = name.index(\"<sup\")           #format to get name\n",
    "                    name = name[:end2-3]\n",
    "                if (\"</b\" in name):\n",
    "                    name = name[:name.index(\"</b\")]\n",
    "                if (\"href\" in name):                    #if name has url\n",
    "                    name = td.find(\"a\").get(\"href\")\n",
    "                    name = td.get_text(\"title\")\n",
    "                if (\"title\" in name):                   #if 'title' in name, take it out\n",
    "                    name = name[:name.index(\"title\")]   #eg \"Keltie Colleentitle[title20title]\"\n",
    "                contestantDict['name'] = name           #add name to dict\n",
    "                \n",
    "            #AGE\n",
    "            if (numtd == 1):\n",
    "                age = str(td.contents)\n",
    "                if (\"<b>\" in age):\n",
    "                    td.find(\"b\")\n",
    "                    age = str(td.contents)[4:-5]\n",
    "                if (\"[u'\" in age):                      \n",
    "                    age = age.encode('utf8')[3:5]\n",
    "                if (age is None):                   #if no age (eg season 9, Cosetta Blanca)\n",
    "                    age = \"na\"\n",
    "                contestantDict['age'] = age\n",
    "                \n",
    "            #HOME\n",
    "            if (numtd == 2):\n",
    "                home = \"\"\n",
    "                for url in td.find_all(\"a\"):        #for each url to a place,\n",
    "                    url.get(\"href\")\n",
    "                    home2 = url.get_text(\"title\")   #get place name\n",
    "                    if (len(home) > 0):             #if already have city,\n",
    "                        home = home + \", \" + home2  #concatenate state\n",
    "                    else:                           #if no city yet (or home is one word),\n",
    "                        home = home2                #save city name or home name\n",
    "\n",
    "                if (\"title\" in home):               #format oddity in season 19, contest 1\n",
    "                    indx = home.index(\"title\")\n",
    "                    home = home[:indx]\n",
    "                if (\"[\" in home):                   #format oddity - homes end in \", [\"\n",
    "                    indx2 = home.index(\"[\")         \n",
    "                    home = home[:indx2-2]\n",
    "                \n",
    "                contestantDict['hometown'] = home\n",
    "\n",
    "                \n",
    "            #OCCUPATION\n",
    "            if (numtd == 3):\n",
    "                job = str(td.contents)\n",
    "                if (\"<b>\" in job):\n",
    "                    td.find(\"b\")\n",
    "                    job = str(td.contents)[4:-5]\n",
    "                if ((\"[u'\" in job) or (\"[u\\\"\" in job)):               \n",
    "                    job = job.encode('utf8')[3:-2]  \n",
    "                if (\"href\" in job):                 #if occupation has url\n",
    "                    job = td.find(\"a\").get(\"href\")\n",
    "                    job = td.get_text(\"title\")\n",
    "                if (\"nowrap\" in job):\n",
    "                    job = td.get_text(\"span\") #, attr={\"class\":\"nowrap\"})\n",
    "                if (\"title\" in job):\n",
    "                    titleindex = job.index(\"title\")\n",
    "                    job = job[:titleindex] + \" \" + job[(titleindex+len(\"title\")):]\n",
    "                if (\"title\" in job):                #sometimes, 'title' appears twice in 'occupation'\n",
    "                    titleindex = job.index(\"title\")\n",
    "                    job = job[:titleindex] + \" \" + job[(titleindex+len(\"title\")):]\n",
    "                if (\"below\" in job):\n",
    "                    job = \"unknown\"\n",
    "                contestantDict['occupation'] = job   \n",
    "                \n",
    "            #ELIMINATION\n",
    "            if (numtd == 4):\n",
    "                elim = str(td.contents)\n",
    "                if (\"<b>\" in elim):\n",
    "                    td.find(\"b\")\n",
    "                    elim = str(td.contents)[4:-5]\n",
    "                if (\"[u'\" in elim):                      \n",
    "                    elim = elim.encode('utf8')[3:-2] \n",
    "                if(\"Eliminated in \" in elim):\n",
    "                    elim = elim[len(\"Eliminated in \"):]\n",
    "                if((\"Quit in \" in elim) or (\"quit in \" in elim)):\n",
    "                    elim = elim[len(\"Quit in \"):]\n",
    "                if((\"Week \" in elim) or (\"week \" in elim)):  #remove \"week\", leave week number only\n",
    "                    elim = elim[len(\"Week \"):]\n",
    "                if ((\"Returned\" in elim) or (\"returned\" in elim)):\n",
    "                    elim = elim[:elim.index(\"', <br/>\")]\n",
    "                contestantDict['elimination'] = elim\n",
    "\n",
    "            numtd += 1\n",
    "        numtr += 1\n",
    "        \n",
    "        contestantDict['season'] = sn   #include season num in dict\n",
    "        \n",
    "        listOfContestantDicts.append(contestantDict) #add dict to list of dicts in this season\n",
    "        listAllDicts.append(contestantDict)         #add dict to list of all dicts in all seasons\n",
    "    seasonsDict[sn] = listOfContestantDicts  #key = season num, val=list of contestant dicts\n",
    "\n",
    "#seasons not added yet: 1-4, 6-8, 20\n",
    "#to test dict so far: print seasonsDict [season][contestant][fieldname], eg:\n",
    "#print seasonsDict[9][10]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the details of each competition for each week\n",
    "# compettionDetails is a dictionary: key = season number, val = list of weekly summary \n",
    "competitionDetails = getCompetitionDetails(wikiPages, seasonsDict) \n",
    "# Get the detailts of each contestants performances for each season\n",
    "# contestantCompData is a dictionary: key = season number, val = dict with contestant \n",
    "# name as keys (values are tuples = (week num [int], date type [str], received rose [bool]))\n",
    "contestantCompData = getContestantCompData(competitionDetails, seasonsDict)\n",
    "# Get each contestants performance for each week of each season\n",
    "# weeklyCompData is a dict: key = season number, val = dict with week number as keys \n",
    "# (values are dict: key = contestant name, val = dict: key=date type val=reeived rose (bool))\n",
    "weeklyCompData = getWeeklyCompData(contestantCompData)\n",
    "# Add the contestantCompData to contestant dictionaries in seasonsDict\n",
    "addCompetitionData(seasonsDict, contestantCompData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the men (the Bachelors) for all seasons. \n",
    "#\n",
    "# FIRST: get all data and add it to a dictionary, one for each bachelor:\n",
    "#     dictionary name = bachelorDict\n",
    "#                keys = name, age, hometown, occupation, elimination=bachelor, season\n",
    "#              values = associated values to fields, as scraped from wiki\n",
    "#\n",
    "#     For example, here is the dictionary for the first bachelor (Season 1):\n",
    "#          {'name': 'Alex Michel', 'hometown': 'Charlottesville, Virginia', \n",
    "#          'age': 32, 'season': '1', 'elimination': 'bachelor', \n",
    "#          'occupation': 'Management consultant'}\n",
    "#\n",
    "# SECOND: add this data to the list that has data for all contestans and bachelors:\n",
    "#      listAllDicts    -   a list of all dicts for all cont and bachelors, all seasons\n",
    "#\n",
    "# Bachelors can be identified easily in this list because their 'elimination' column value \n",
    "# is 'bachelor' (whereas contestants have 'elimination' column values 'runner-up', or \n",
    "# '7' for week seven).\n",
    "#\n",
    "\n",
    "#go to wiki homepage for The Bachelor, make soup element\n",
    "allseasons = requests.get(\"https://en.wikipedia.org/wiki/The_Bachelor_(U.S._TV_series)#Seasons\")\n",
    "soup = BeautifulSoup(allseasons.text, \"html.parser\") \n",
    "\n",
    "#get the table cell that has links to each episode\n",
    "men = soup.find(\"table\", attrs={\"class\":\"wikitable plainrowheaders\"})\n",
    "men = men.find_all(\"tr\")\n",
    "\n",
    "numRow = 0\n",
    "for man in men:                                 #for each bachelor in the table,\n",
    "    bachelorDict = dict()                       #init new dict for this bachelor\n",
    "    bachAge = \"unknown\"                         #default values for those we can't find\n",
    "    bachHometown = \"unknown\"\n",
    "    bachOccupation = \"unknown\"\n",
    "    if (numRow == 0):                           #skip first row - col titles\n",
    "        numRow += 1\n",
    "        continue\n",
    "    if (numRow > 19):                           #don't collect data on Season 20 Bachelor\n",
    "        break\n",
    "        \n",
    "    numCol = 0\n",
    "    for col in man.find_all(\"td\"):              #for each col in this bachelor row,       \n",
    "\n",
    "        #SEASON NUMBER\n",
    "        if (numCol == 0):                              \n",
    "            seasonNum = col.get_text()\n",
    "            seasonNum = seasonNum.encode('utf8')\n",
    "        \n",
    "        if (numCol == 1):                       #get season year (to calculate age later)\n",
    "            col = col.get_text()\n",
    "            if (\"[\" in col):\n",
    "                seasonYear =  col.encode('utf8')[-8:-4]\n",
    "            else:\n",
    "                seasonYear =  col.encode('utf8')[-4:]\n",
    "        \n",
    "        #Get URL for bachelor's personal site, make soup element \n",
    "        if (numCol == 2):                               \n",
    "            manURL = col.find(\"a\").get(\"href\")\n",
    "            manPage = requests.get(\"https://en.wikipedia.org\" + manURL)\n",
    "            bachSoup = BeautifulSoup(manPage.text, \"html.parser\") \n",
    "            manSoup = bachSoup.find(\"table\", attrs={\"class\":\"infobox biography vcard\"})\n",
    "            if (manSoup is None):\n",
    "                manSoup = bachSoup.find(\"table\", attrs={\"class\":\"infobox vcard\"})\n",
    "            if (manSoup is not None):\n",
    "                manSoup = manSoup.find_all(\"tr\")\n",
    "            \n",
    "                #go to 'biography box' on bachelor's personal site\n",
    "                bioRow = 0\n",
    "                for row in manSoup:\n",
    "                    #BACHELOR AGE\n",
    "                    bornYear = row.find(\"span\", attrs={\"class\":\"bday\"})\n",
    "                    if (bornYear is not None):\n",
    "                        bornYear = bornYear.get_text()\n",
    "                        bornYear = bornYear.encode('utf8')[:4]\n",
    "                        bachAge = int(seasonYear) - int(bornYear)   #calculate age\n",
    "                    \n",
    "                    #BACHELOR HOMETOWN\n",
    "                    bachHome = row.find(\"span\", attrs={\"class\":\"birthplace\"})\n",
    "                    if (bachHome is None):\n",
    "                        bachHome = row.find(\"td\", attrs={\"class\":\"birthplace\"})\n",
    "                    if (bachHome is not None):\n",
    "                        bachHometown = bachHome.find(\"a\") #.get(\"href\")\n",
    "                        bachHometown = str(bachHometown.contents[0])\n",
    "                    if (\"New York City\" in bachHometown):\n",
    "                        bachHometown = \"New York City, New York\"\n",
    "\n",
    "                    bioRow += 1\n",
    "\n",
    "            #BACHELOR NAME\n",
    "            bachName = col.get_text()\n",
    "            bachName = bachName.encode('utf8')\n",
    "            if (\"[\" in bachName):\n",
    "                bachName = bachName[:-4]\n",
    "                \n",
    "\n",
    "        #BACHELOR OCCUPATION\n",
    "        if (numCol == 3):                               \n",
    "            bachOccupation = col.get_text()      \n",
    "            bachOccupation = bachOccupation.encode('utf8')\n",
    "            \n",
    "        numCol += 1\n",
    "    \n",
    "    #hard-code data for Bachelors who don't have own wiki page\n",
    "    if (\"Grant\" in bachName):\n",
    "        bachHometown = \"London, UK\"\n",
    "        bachAge = \"27\"\n",
    "    if (\"Womack\" in bachName):\n",
    "        bachHometown = \"Austin, Texas\"\n",
    "        bachAge = \"37\" \n",
    "    if (\"Flajnik\" in bachName):\n",
    "        bachHometown = \"Sonoma, California\"\n",
    "        bachAge = \"28\" \n",
    "    if (\"Soules\" in bachName):\n",
    "        bachHometown = \"Arlington, Iowa\"\n",
    "        bachAge = \"33\"\n",
    "    if (\"Palmer\" in bachName):\n",
    "        bachHometown = \"Toronto, Ontario\"\n",
    "    \n",
    "    #add info to bachelor dictionary\n",
    "    bachelorDict['name'] = bachName  \n",
    "    bachelorDict['age'] = bachAge\n",
    "    bachelorDict['hometown'] = bachHometown\n",
    "    bachelorDict['occupation'] = bachOccupation\n",
    "    bachelorDict['elimination'] = \"bachelor\"\n",
    "    bachelorDict['season'] = int(seasonNum.encode('utf8'))\n",
    "    \n",
    "    #add bachelor dictionary to list of all dicts for all people in all seasons\n",
    "    listAllDicts.append(bachelorDict)         \n",
    "    \n",
    "    numRow +=1  #get next bachelor from wiki table\n",
    "    \n",
    "    \n",
    "#Non-wiki Data sources:\n",
    "#Grant: http://www.realitytvworld.com/news/matt-grant-dishes-on-upcoming-the-bachelor-london-calling-finale-7066.php\n",
    "#Womack: http://www.people.com/people/article/0,,20429663,00.html\n",
    "#Soules:http://www.people.com/article/chris-soules-new-bachelor-in-love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS A NOTE - DELETE CELL BEFORE TURNING IN.\n",
    "\n",
    "# Haven't found data for seasons 1, 3, 7.  Below are notes on these seasons, including data on winners.\n",
    "\n",
    "# SEASON 1 \n",
    "# WINNER - Amanda Marsh, a 23-year-old event planner from Chanute, Kansas\n",
    "# \n",
    "# first names: Kim, Cathy, Trista, Amy, Alexa, LaNease, Tina, Angelique, Rhonda, \n",
    "#             Christina, Katie, Amanda, Angela, Melissa, Shannon\n",
    "# source for winner: http://www.courant.com/hc-amandawinner-ph-photo.html\n",
    "\n",
    "\n",
    "# SEASON 3 \n",
    "# WINNER - Jen Schefft, a 26-year-old publicist from Mentor, Ohio\n",
    "#\n",
    "# names: jen schefft, kirsten Buschbacher, Tina Panas, Cristina Costa, Anne-Michelle Seiler,\n",
    "# Liz Terzo, Amber Stoke, Audree Shelton, Heather Barry, Tina Sevier, Amy Plinska,\n",
    "# Christina Sztanko, Elizabeth, Rachel, Shannon Ford, Amy Greenspan, Angela Polimeri,\n",
    "# Brooke Vermeulen, Courtney Chan, Ginny Edwards, Jennifer Buttacavoli, Kerri, Kristen,\n",
    "# Stephanie, Tiffany Sandels\n",
    "#\n",
    "# source: http://www.tvsa.co.za/shows/viewshowseasons.aspx?showId=2925&season=3\n",
    "# source for first names: http://www.realitywanted.com/shows/the-bachelor/season-8-paris\n",
    "\n",
    "\n",
    "# SEASON 7\n",
    "# WINNER: Sarah Brice, a 24-year-old nurse from McKinney, Texas\n",
    "#\n",
    "# first names: \n",
    "# Anitra, elim episode 4\n",
    "# Brenda, elim episode 1\n",
    "# Carrie, elim episode 2\n",
    "# Danushka, elim episode 1\n",
    "# Emilie, elim episode 1\n",
    "# Geitan, elim episode 1\n",
    "# Gina-Marie,elim episode 2\n",
    "# Heather,elim episode 1\n",
    "# Jenny, elim episode 3\n",
    "# Kara, elim episode 3\n",
    "# Katie, elim episode 1\n",
    "# Kerry, elim episode 2\n",
    "# Kimberley, elim episode 5\n",
    "# Kindle, elim episode 4\n",
    "# Kristen, elim episode 1\n",
    "# Kristina, elim episode 1\n",
    "# Kyshawn, elim episode 1\n",
    "# Megan, elim episode 2\n",
    "# Siomara, elim episode 1\n",
    "# Valerie, elim episode 1\n",
    "# Sarah Welchelim episode 6\n",
    "#\n",
    "# source for names and elim episodes: http://tvdatabase.wikia.com/wiki/Category:Bachelor\n",
    "# source for winner Brice: http://www.realitytvworld.com/news/abc-bachelor-charlie-oconnell-picks-sarah-brice-rejects-krisily-kennedy-in-seventh-season-finale-3504.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data for Seasons 2, 4 and 6.\n",
    "#\n",
    "# Despite much effort, I could not get the text from the'realitytvword.com' sources below.\n",
    "# The Beautiful Soup elements did not match the \"inspect element\" html tags.  \n",
    "# (Oddly, I was able to scrape from 'realitytv.about.com' for season 8 - see below.)\n",
    "#\n",
    "# I tried the following suggestions, but they did not work:\n",
    "#    https://www.reddit.com/r/learnpython/comments/2nqhzw/how_come_a_websites_page_source_html_is_different/\n",
    "#    http://stackoverflow.com/questions/26913316/beautiful-soup-doesnt-get-full-webpage\n",
    "# To keep on schedule, I hand-entered the data. If time permits, I will come back to this.\n",
    "#\n",
    "# SEASON 2 SOURCES\n",
    "# 1) http://www.realitytvworld.com/#$$nxtmgs&&BYitVosLEeWjwgrBiYTF8Q$$\n",
    "# 2) winner: http://www.realitywanted.com/shows/the-bachelor/season-2\n",
    "#\n",
    "# SEASON 4 SOURCES\n",
    "# 1) http://www.realitytvworld.com/#$$nxtgih&&Dvr38or5EeW1VRL/9wgFGw$$\n",
    "# 2) http://draheid.com/archives/bachelor4/messages/1452262/1105037.html\n",
    "# 3) winner: http://www.realitywanted.com/shows/the-bachelor/season-4\n",
    "#\n",
    "# SEASON 6 SOURCES\n",
    "# 1) Source:(looks different in Safari versus Chrome) http://www.realitytvworld.com/#$$nxt6je&&9hhYJIraEeWixQqIPWP/qw$$\n",
    "# 2) Alt. Source: http://www.realitytvworld.com/news/abc-releases-identities-of-sixth-bachelor-edition-bachelorettes-2880.php\")\n",
    "# 3) FYI, source without occupations, but with pictures: \n",
    "# (http://community.realitytvworld.com/cgi-sys/cgiwrap/rtvw2/community/dcboard.cgi?az=printer_format&om=894&forum=DCForumID42)\n",
    "# 4) Source of winner name: http://www.realitywanted.com/shows/the-bachelor/season-6\n",
    "# 5) Mary Delgado source: http://www.sptimes.com/2003/09/26/Tampabay/No_wedding_bells__jus.shtml\n",
    "#\n",
    "\n",
    "#make array of data for contestants in Season 2\n",
    "season2 = [\"Heather, a 23-year-old sales coordinator who currently resides in Walnut Creek, CA\",  \n",
    "\"Lori, a 26-year-old public relations representative who currently resides in Dallas, TX\",  \n",
    "\"Heather, a 30-year-old flight attendant who currently resides in Watauga, TX\",  \n",
    "\"Amber, a 25-year-old therapist who currently resides in Chapel Hill, NC\",  \n",
    "\"Cari, a 28-year-old elementary school teacher who currently resides in Granite City, IL\",  \n",
    "\"Christy, a 24-year-old radiologic technologist who currently resides in Avondale, AZ\",  \n",
    "\"Hayley, a 28-year-old store manager who currently resides in Dana Point, CA\",  \n",
    "\"Camille, a 29-year-old actress/model who currently resides in Los Angeles, CA\",  \n",
    "\"Kyla Faye, a 22-year-old recording artist who currently resides in Midvale, UT\",  \n",
    "\"Erin, a 25-year-old national magazine who currently resides in Chester, PA\",  \n",
    "\"Frances, a 30-year-old strategic planning analyst who currently resides in San Francisco, CA\",  \n",
    "\"Dana, a 24-year-old radio sales who currently resides in Beverly Hills, CA\",  \n",
    "\"Merrilee, a 27-year-old teacher who currently resides in Forked River, NJ\",  \n",
    "\"Suzi, a 27-year-old communications specialist who currently resides in Richmond, VA\",  \n",
    "\"Anindita, a 27-year-old attorney who currently resides in New York, NY\",  \n",
    "\"Fatima, a 22-year-old student who currently resides in Long Beach, CA\",  \n",
    "\"Helene Eksterowicz, a 27-year-old school psychologist who currently resides in Glouchester, NJ\",  \n",
    "\"Brooke Nicole, a 22-year-old student who currently resides in Tuscaloosa, AL\",  \n",
    "\"Liangy, a 30-year-old paralegal who currently resides in Coral Gables, FL\",  \n",
    "\"Erin, a 23-year-old interior designer who currently resides in Houston, TX\",  \n",
    "\"Suzanne, a 32-year-old flight attendant who currently resides in Redondo Beach, CA\",  \n",
    "\"Angela, a 26-year-old registered nurse who currently resides in Kansas City, MO\",  \n",
    "\"Shannon, a 25-year-old graphic artist who currently resides in Hicksville, NY\",  \n",
    "\"Christi Diane, a 23-year-old financial advisors asst. who currently resides in Eagle, ID\",  \n",
    "\"Gwen, a 31-year-old executive recruiter who currently resides in Chester Springs, PA\"] \n",
    "\n",
    "\n",
    "#make array of data for contestants in Season 4\n",
    "season4= [\"Brooke, a 24-year-old Teacher who currently resides in Bartlett, TN\", \n",
    "\"Lee-Ann, a 24-year-old Second Grade Teacher who currently resides in  Athens, GA\", \n",
    "\"Shea, a 25-year-old Firefighter who currently resides in Shreveport, LA\", \n",
    "\"Mary, a 35-year-old Sales Manager who currently resides in Tampa, FL\", \n",
    "\"Lindsay, a 23-year-old Professional Dancer who currently resides in Los Angeles, CA\", \n",
    "\"Estella Gardinier, a 27-year-old Mortgage Broker who currently resides in Beverly Hills, CA\", \n",
    "\"Lanah, a 27-year-old Event Coordinator who currently resides in Poolesville, MD\", \n",
    "\"Jenny, a 30-year-old Marketing Director who currently resides in Austin, TX\", \n",
    "\"Kristi, a 24-year-old Loan Processor who currently resides in Chicago, IL\", \n",
    "\"Lindsay, a 25-year-old Pharmaceutical Sales who currently resides in Mauldin, SC\", \n",
    "\"Shelly, a 26-year-old Pharmaceutical Sales who currently resides in Wanwatosa, WI\", \n",
    "\"Kelly Jo, a 23-year-old Director of Community Relations who currently resides in  Kalamazoo, MI\", \n",
    "\"Antoinette, a 30-year-old Senior Account Manager who currently resides in Philadelphia, PA\", \n",
    "\"Stacey, 26-year-old a Hair Stylist who currently resides in  Massillon, OH\", \n",
    "\"Heather, a 24-year-old Recent College Graduate who currently resides in Chicago, IL\",\n",
    "\"Meredith, a 29-year-old Model/ Makeup Artist who currently resides in West Hollywood, CA\", \n",
    "\"Misty, a 23-year-old Radio Promotions Assistant who currently resides in Dallas, TX\", \n",
    "\"Christine, a 24-year-old Administrative Assistant who currently resides in Corona, CA\", \n",
    "\"Jenn, a 26-year-old Elementary School Teacher who currently resides in La Jolla, CA\", \n",
    "\"Leona, a 25-year-old Realtor's Assistant who currently resides in Chicago, IL\", \n",
    "\"Samantha, a 25-year-old Kitchen Designer who currently resides in Chicago, IL\", \n",
    "\"Julie, a 29-year-old Sales/ Modeling who currently resides in Louisville, KY\", \n",
    "\"Karin, a 32-year-old Mortgage Consultant who currently resides in Brooklyn Park, MN\", \n",
    "\"Lauren, a 24-year-old Retail Buyer who currently resides in Redondo Beach, CA\", \n",
    "\"Darla, a 26-year-old Attorney who currently resides in Gainesville, FL\"] \n",
    "\n",
    "#make array of data for contestants in Season 6\n",
    "season6 = [\"Abby, a 29-year-old acrobat who currently resides in Henderson, NV\", \n",
    "\"Alma Rubenstein, a 35-year-old cafe owner who currently resides in Astoria, OR\",\n",
    "\"Amanda, a 27-year-old cosmetics buyer who currently resides in New York, NY\", \n",
    "\"Amy, a 27-year-old marketing consultant who currently resides in San Diego, CA\", \n",
    "\"Andrea, a 33-year-old dental hygienist who currently resides in Denver, CO\", \n",
    "\"Ashley, a 31-year-old teacher who currently resides in Santa Barbara, CA\", \n",
    "\"Carolyn, a 36-year-old financial advisor who currently resides in Tulsa, OK\", \n",
    "\"Cheresse, a 31-year-old advertising director who currently resides in St. Louis, MO\", \n",
    "\"Cynthia, a 37-year-old charity foundations director who currently resides in Hermosa Beach, CA\", \n",
    "\"Elizabeth, a 28-year-old in pharmaceutical sales who currently resides in Chicago, IL\", \n",
    "\"Jayne, a 37-year-old dog groomer, who currently resides in Key Largo, FL\",\n",
    "\"Jennifer, a 31-year-old account executive who currently resides in Seattle, WA\", \n",
    "\"Kelly, a 34-year-old actress who currently resides in Beverly Hills, CA\", \n",
    "\"Kerry, a 31-year-old nurse who currently resides in San Francisco, CA\", \n",
    "\"Kristie, a 32-year-old bar owner who currently resides in Windsor, Canada\", \n",
    "\"Kristin, a 27-year-old office manager who currently resides in Pensacola, FL\", \n",
    "\"Krysta, a 28-year-old financial analyst who currently resides in Oklahoma City, OK\", \n",
    "\"Leina, a 28-year-old advertising associate who currently resides in Chula Vista, CA\", \n",
    "\"Lisa, a 33-year-old teacher who currently resides in West Palm Beach, FL\", \n",
    "\"Melinda, a 39-year-old photographer who currently resides in Nashville, TN\", \n",
    "\"Natalie, a 34-year-old in retail sales who currently resides in Santa Monica, CA\", \n",
    "\"Nicole, a 28-year-old executive recruiter who currently resides in Libertyville, IL\", \n",
    "\"Susie, a 32-year-old insurance broker who currently resides in Hollywood, CA\", \n",
    "\"Tanya, a 31-year-old teacher who currently resides in Plano, Texas\", \n",
    "\"Wende, a 28-year-old model who currently resides in Austin, Texas\",\n",
    "\"Mary Delgado, a 35-year-old real estate agent who currently resides in Tampa Bay, FL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add contestant data for seasons 2, 4 and 6 to dictionary 'contestantDict'.\n",
    "#\n",
    "# param : array of strings with contestant data\n",
    "# param : season number\n",
    "# param : winner name\n",
    "def addNonWikiData(contestantArray, seasonNum, winnerName):\n",
    "    for line in contestantArray:\n",
    "        firstComma = line.index(',')                    #parse string\n",
    "        startAge = line.index(\" a \")\n",
    "        jobTag = \"year-old \"     \n",
    "        startJob = line.index(jobTag)\n",
    "        homeTag = \"currently resides in \"\n",
    "        startHome = line.index(homeTag)\n",
    "        contestantDict = dict()                        #init new dict for contestant   \n",
    "        contestantDict['name'] = line[:firstComma]     #put field data into dictionary\n",
    "        contestantDict['age'] = line[startAge+3:startAge+5]\n",
    "        contestantDict['hometown'] = line[startHome + len(homeTag):]\n",
    "        contestantDict['occupation'] = line[startJob + len(jobTag):line.index(\"who\")-1]\n",
    "        contestantDict['season'] = seasonNum\n",
    "    \n",
    "        if (winnerName in line):                       #if this is the Winner,\n",
    "            contestantDict['elimination'] = \"Winner\"   #add 'winner' to 'elimination' field\n",
    "        else:\n",
    "            contestantDict['elimination'] = \"unknown\"\n",
    "        listOfContestantDicts.append(contestantDict)   #add dict to list of dicts for this season\n",
    "        listAllDicts.append(contestantDict)           #add dict to list of all dicts in all seasons\n",
    "           \n",
    "    seasonsDict[seasonNum] = listOfContestantDicts     #key = season, val=list of contestant dicts\n",
    "    \n",
    "    \n",
    "#add contestant data for seasons 4 and 6 to the contestant dictionary\n",
    "addNonWikiData(season2, 2, \"Eksterowicz\")\n",
    "addNonWikiData(season4, 4, \"Gardinier\")\n",
    "addNonWikiData(season6, 6, \"Delgado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data for Season 8, add to dictionary\n",
    "\n",
    "#get site with season 8 contestants, make soup element\n",
    "seasonEight = requests.get(\"http://realitytv.about.com/od/thebachelor8/ig/Ladies-of-The-Bachelor--Paris/\")                #get site\n",
    "season8= BeautifulSoup(seasonEight.text, \"html.parser\")\n",
    "\n",
    "#get the table cell that has links to each episode\n",
    "eight = season8.find(\"body\", attrs={\"id\":\"imagegalleryIndexPage\"})\n",
    "eight = eight.find(\"main\", attrs={\"id\":\"main\"})\n",
    "eight = eight.find(\"div\", attrs={\"class\":\"container\"})\n",
    "eight = eight.find_all(\"div\", attrs={\"class\":\"row\"})[1]\n",
    "eight = eight.find(\"div\", attrs={\"class\":\"col col-11\"}).find(\"div\", attrs={\"class\":\"row\"})\n",
    "eight = eight.find(\"div\", attrs={\"class\":\"col col-8\"})\n",
    "eight = eight.find(\"div\", attrs={\"class\":\"content widget gallery-index-content\"})\n",
    "eight = eight.find(\"ul\")\n",
    "\n",
    "urls8 = []                       #list of urls for season 8 contestant pages\n",
    "for item in eight.find_all(\"li\", attrs={\"itemtype\":\"http://schema.org/ImageObject\"}):#for each contestant in list of season 8 contestants\n",
    "    url8 = item.find(\"a\")        #get url tag\n",
    "    if url8 is not None:         #if has url link, get url \n",
    "        urls8.append(\"\\\"http://realitytv.about.com\" + url8.get(\"href\") + \"\\\"\")\n",
    "\n",
    "#add contestant site leftover from next page\n",
    "urls8.append(\"\\\"http://realitytv.about.com/od/thebachelor8/ig/Ladies-of-The-Bachelor--Paris/Shiloh-of-The-Bachelor--Paris.htm\\\"\")  \n",
    "\n",
    "\n",
    "cont8Sites = []                  #list of soup objects for season 8 contestant sites\n",
    "for link in urls8:\n",
    "    site8 = requests.get(link[1:-1]) \n",
    "    soup8 = BeautifulSoup(site8.text, \"html.parser\") #get soup element\n",
    "    cont8Sites.append(soup8)     #add soup element to list     \n",
    "\n",
    "for cont8 in cont8Sites:         #for each soup element (one per contestant site),\n",
    "    c8 = cont8.find(\"body\", attrs={\"id\":\"imagegalleryPage\"}) #find data\n",
    "    c8 = c8.find(\"main\", attrs={\"class\":\"slab\"})\n",
    "    c8 = c8.find(\"div\", attrs={\"class\":\"container\"})\n",
    "    c8 = c8.find_all(\"div\", attrs={\"class\":\"row\"})[1]\n",
    "    c8 = c8.find(\"div\", attrs={\"class\":\"col col-11\"})\n",
    "    c8 = c8.find(\"div\", attrs={\"id\":\"contentIntro\"})\n",
    "    c8 = c8.find(\"div\", attrs={\"class\":\"row\"})\n",
    "    c8 = c8.find(\"div\", attrs={\"class\":\"col col-6\"})\n",
    "    c8 = c8.find(\"div\", attrs={\"class\":\"muted subheading\"}).getText()\n",
    "    \n",
    "    contestantDict = dict()     #init new dict for contestant\n",
    "\n",
    "    #get name\n",
    "    firstComma = c8.index(',')\n",
    "    contestantDict['name'] = c8[:firstComma]\n",
    "        \n",
    "    #get age\n",
    "    substrC8 = c8[firstComma+2:]\n",
    "    secondComma = substrC8.index(',')\n",
    "    contestantDict['age'] = substrC8[:secondComma]\n",
    "        \n",
    "    #get hometown\n",
    "    hometag = \"resides in \"\n",
    "    if (hometag not in c8):\n",
    "        hometag = \"living in \"\n",
    "    homeIndex = c8.index(hometag)\n",
    "    contestantDict['hometown'] = c8[(homeIndex+len(hometag)):-1]\n",
    "        \n",
    "    #get job\n",
    "    jobtag = \"is a \"\n",
    "    endjobtag = \" who\"\n",
    "    if (\"is an\" in c8):\n",
    "        jobtag = \"is an \"\n",
    "    if(\"works in\" in c8):   #has format \"Tara, 23, works in X and currently resides in Y\"\n",
    "        jobtag = \"works in \"\n",
    "        endjobtag = \" and currently resides\"\n",
    "    if(\"is the\" in c8):\n",
    "        jobtag = \"is the \"\n",
    "        endjobtag = \" and currently resides\"\n",
    "    if (endjobtag not in c8):\n",
    "        endjobtag = \" living in\"\n",
    "    contestantDict['occupation'] = c8[(c8.index(jobtag)+len(jobtag)):(c8.index(endjobtag))]   #add name to dict\n",
    "\n",
    "    #get elimination week\n",
    "    if (\"Sarah Stone\" in name):         #hard-code season 8 winner\n",
    "        contestantDict['elimination'] = \"Winner\"\n",
    "    else:\n",
    "        contestantDict['elimination'] = \"unknown\"\n",
    "    \n",
    "    #add season\n",
    "    contestantDict['season'] = 8\n",
    "        \n",
    "    #add dict to list of dicts\n",
    "    #if (contestantDict not in newList):\n",
    "    listOfContestantDicts.append(contestantDict) #add dict to list of dicts in this season\n",
    "    listAllDicts.append(contestantDict)  #add dict to list of all dicts in ALL seasons\n",
    "\n",
    "seasonsDict[8] = listOfContestantDicts  #key = season num, val=list of contestant dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listAllDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if want to save dictionary to disk  -- otherwise, delete this cell before handing in\n",
    "\n",
    "import json\n",
    "fd = open(\"tempdata/seasonsDict.json\", \"w\")   #save dictionary to disk\n",
    "json.dump(seasonsDict, fd)\n",
    "fd.close()\n",
    "\n",
    "#del seasonsDict\n",
    "#with open(\"tempdata/seasonsDict.json\", \"r\") as fd: \n",
    "#    seasonsDict = json.load(fd)               #reload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>elimination week</th>\n",
       "      <th>group_dates</th>\n",
       "      <th>hometown</th>\n",
       "      <th>individual_dates</th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>roses_from_group_dates</th>\n",
       "      <th>roses_from_individual_dates</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Winner</td>\n",
       "      <td>2</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>Melissa Rycroft</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Runner-up</td>\n",
       "      <td>1</td>\n",
       "      <td>Grand Rapids, Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>Molly Malaney</td>\n",
       "      <td>Department Store Buyer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Peace River, Alberta</td>\n",
       "      <td>1</td>\n",
       "      <td>Jillian Harris</td>\n",
       "      <td>Interior Designer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Carlsbad, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Naomi Rose Crespo</td>\n",
       "      <td>Flight Attendant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Huntsville, Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>Stephanie Hogan</td>\n",
       "      <td>Single Mother &amp; Medical Marketing Rep.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age elimination week  group_dates                hometown  individual_dates               name                              occupation  roses_from_group_dates  roses_from_individual_dates  season\n",
       "0  25           Winner            2           Dallas, Texas                 1    Melissa Rycroft                    Sales Representative                       0                            1      13\n",
       "1  24        Runner-up            1  Grand Rapids, Michigan                 1      Molly Malaney                  Department Store Buyer                       1                            1      13\n",
       "2  29                7            2    Peace River, Alberta                 1     Jillian Harris                       Interior Designer                       0                            0      13\n",
       "3  24                6            3    Carlsbad, California                 0  Naomi Rose Crespo                        Flight Attendant                       1                            0      13\n",
       "4  34                5            0     Huntsville, Alabama                 2    Stephanie Hogan  Single Mother & Medical Marketing Rep.                       0                            2      13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert list of contestant dictionaries to a pandas dataframe.\n",
    "#\n",
    "# Note: 'listAllDicts' has seasons = [2,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19] \n",
    "# Here, we make a dataframe of Seasons 13 forward.\n",
    "#\n",
    "\n",
    "cDicts = []                  \n",
    "for l in listAllDicts:\n",
    "    if (l['season'] > 12):       #for seasons 13 forward,\n",
    "        d={}\n",
    "        d['name']=l['name']\n",
    "        d['age']=l['age']\n",
    "        d['hometown']=l['hometown']\n",
    "        d['occupation']=l['occupation']\n",
    "        d['elimination week']=l['elimination']  #for bachelors, value will be 'bachelor'\n",
    "        if 'group_dates' in l and 'individual_dates' in l:\n",
    "            d['group_dates'] = l['group_dates']\n",
    "            d['individual_dates'] = l['individual_dates']\n",
    "            d['roses_from_group_dates'] = l['roses_from_group_dates']\n",
    "            d['roses_from_individual_dates'] = l['roses_from_individual_dates']\n",
    "        else:\n",
    "            d['group_dates'] = 0\n",
    "            d['individual_dates'] = 0\n",
    "            d['roses_from_group_dates'] = 0\n",
    "            d['roses_from_individual_dates'] = 0\n",
    "        d['season']=l['season']\n",
    "        cDicts.append(d)\n",
    "        \n",
    "contestantDF = pd.DataFrame(cDicts)\n",
    "contestantDF.drop_duplicates()  #drop duplicates, just in case\n",
    "contestantDF.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contestantDF.shape      #print (number of contestants and bachelors for seasons > 12) x (number of fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>elimination week</th>\n",
       "      <th>group_dates</th>\n",
       "      <th>hometown</th>\n",
       "      <th>individual_dates</th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>roses_from_group_dates</th>\n",
       "      <th>roses_from_individual_dates</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Winner</td>\n",
       "      <td>2</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>Melissa Rycroft</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Runner-up</td>\n",
       "      <td>1</td>\n",
       "      <td>Grand Rapids, Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>Molly Malaney</td>\n",
       "      <td>Department Store Buyer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Peace River, Alberta</td>\n",
       "      <td>1</td>\n",
       "      <td>Jillian Harris</td>\n",
       "      <td>Interior Designer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Carlsbad, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Naomi Rose Crespo</td>\n",
       "      <td>Flight Attendant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Huntsville, Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>Stephanie Hogan</td>\n",
       "      <td>Single Mother &amp; Medical Marketing Rep.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Marlboro, New Jersey</td>\n",
       "      <td>0</td>\n",
       "      <td>Lauren Wanger</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Sewickley, Pennsylvania</td>\n",
       "      <td>0</td>\n",
       "      <td>Megan Parris</td>\n",
       "      <td>Single Mother and Lacrosse Coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Marshall, Missouri</td>\n",
       "      <td>0</td>\n",
       "      <td>Shannon Bair</td>\n",
       "      <td>Dental Hygienist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Blue Island, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicole \"Nikki\" Kaapke</td>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Monroe, Connecticut</td>\n",
       "      <td>0</td>\n",
       "      <td>Erica</td>\n",
       "      <td>Account Executive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age elimination week  group_dates                 hometown  individual_dates                   name                              occupation  roses_from_group_dates  roses_from_individual_dates  season\n",
       "0  25           Winner            2            Dallas, Texas                 1        Melissa Rycroft                    Sales Representative                       0                            1      13\n",
       "1  24        Runner-up            1   Grand Rapids, Michigan                 1          Molly Malaney                  Department Store Buyer                       1                            1      13\n",
       "2  29                7            2     Peace River, Alberta                 1         Jillian Harris                       Interior Designer                       0                            0      13\n",
       "3  24                6            3     Carlsbad, California                 0      Naomi Rose Crespo                        Flight Attendant                       1                            0      13\n",
       "4  34                5            0      Huntsville, Alabama                 2        Stephanie Hogan  Single Mother & Medical Marketing Rep.                       0                            2      13\n",
       "5  27                4            2     Marlboro, New Jersey                 0          Lauren Wanger                                 Teacher                       0                            0      13\n",
       "6  25                4            2  Sewickley, Pennsylvania                 0           Megan Parris        Single Mother and Lacrosse Coach                       0                            0      13\n",
       "7  29                4            2       Marshall, Missouri                 0           Shannon Bair                        Dental Hygienist                       0                            0      13\n",
       "8  29                4            0    Blue Island, Illinois                 0  Nicole \"Nikki\" Kaapke                Administrative Assistant                       0                            0      13\n",
       "9  25                3            2      Monroe, Connecticut                 0                  Erica                       Account Executive                       0                            0      13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contestantDF.head(10)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>elimination week</th>\n",
       "      <th>group_dates</th>\n",
       "      <th>hometown</th>\n",
       "      <th>individual_dates</th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>roses_from_group_dates</th>\n",
       "      <th>roses_from_individual_dates</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Shelby Charter Township, Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>Cassandra Ferguson</td>\n",
       "      <td>Former NBA Dancer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Orland Park, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Alli Restko</td>\n",
       "      <td>Nanny</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Litchfield, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Danielle Ronco</td>\n",
       "      <td>Psychiatric Nurse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Conyers, Georgia</td>\n",
       "      <td>0</td>\n",
       "      <td>Kelly Travis</td>\n",
       "      <td>Dog Lover</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Forty Fort, Pennsylvania</td>\n",
       "      <td>0</td>\n",
       "      <td>Elise Mosca</td>\n",
       "      <td>First Grade Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>0</td>\n",
       "      <td>Lauren Solomon</td>\n",
       "      <td>Music Composer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Aurora, Illinois</td>\n",
       "      <td>1</td>\n",
       "      <td>Christy Hansen</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Santa Barbara, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>Free Spirit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Clermont, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Amy Long</td>\n",
       "      <td>Local News Reporter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Miami, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Chantel Forrest</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Porto Alegre, Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>Victoria Lima</td>\n",
       "      <td>Legal Assistant</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tampa, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Alexis Morgado</td>\n",
       "      <td>Communications Director/ NHL  Ice Girl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Apopka, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Amy Jokinen</td>\n",
       "      <td>Massage Therapist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Roanoke, Texas</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashley Poe</td>\n",
       "      <td>Grade School Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Miami, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Christine Llano</td>\n",
       "      <td>Police Support Specialist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Rockford, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Kylie Lewis</td>\n",
       "      <td>Interior Designer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Antelope Acres, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Lacy Faddoul</td>\n",
       "      <td>Nursing Home Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Edmond, Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>Lauren Higginson</td>\n",
       "      <td>Mineral Coordinator</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Wagener, South Carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>Maggie Gantt</td>\n",
       "      <td>Personal Banker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sutter, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Valerie Eredia</td>\n",
       "      <td>Personal Trainer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>29</td>\n",
       "      <td>Winner</td>\n",
       "      <td>1</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1</td>\n",
       "      <td>Whitney Bischoff</td>\n",
       "      <td>Fertility Nurse</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>26</td>\n",
       "      <td>Runner-up</td>\n",
       "      <td>2</td>\n",
       "      <td>Shreveport, Louisiana</td>\n",
       "      <td>1</td>\n",
       "      <td>Becca Tilley</td>\n",
       "      <td>Chiropractic Assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Leduc, Alberta</td>\n",
       "      <td>1</td>\n",
       "      <td>Kaitlyn Bristowe</td>\n",
       "      <td>Dance Instructor</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Gering, Nebraska</td>\n",
       "      <td>1</td>\n",
       "      <td>Jade Roper</td>\n",
       "      <td>Cosmetics Developer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Arlington, Texas</td>\n",
       "      <td>0</td>\n",
       "      <td>Carly Waddell</td>\n",
       "      <td>Cruise Ship Singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Hollywood, California</td>\n",
       "      <td>1</td>\n",
       "      <td>Britt Nilsson</td>\n",
       "      <td>Waitress</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Nashville, Tennessee</td>\n",
       "      <td>1</td>\n",
       "      <td>Megan Bell</td>\n",
       "      <td>Make-Up Artist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Hudsonville, Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>Kelsey Poe</td>\n",
       "      <td>Guidance Counselor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Great Falls, Virginia</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashley Iaconetti</td>\n",
       "      <td>Nanny/Freelance Journalist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Maple Valley, Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>Mackenzie Deonigi</td>\n",
       "      <td>Dental Assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Indianapolis, Indiana</td>\n",
       "      <td>0</td>\n",
       "      <td>Samantha Steffen</td>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Brooklyn, New York</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashley Salter</td>\n",
       "      <td>Hair Stylist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Portland, Oregon</td>\n",
       "      <td>0</td>\n",
       "      <td>Juelia Kinney</td>\n",
       "      <td>Esthetician</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>0</td>\n",
       "      <td>Nikki Delventhal</td>\n",
       "      <td>Former NFL Cheerleader</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Howland, Ohio</td>\n",
       "      <td>0</td>\n",
       "      <td>Jillian Anderson</td>\n",
       "      <td>News Producer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Kankakee, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Amber James</td>\n",
       "      <td>Bartender</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Wellington, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Tracy Darakis</td>\n",
       "      <td>Fourth Grade Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Algonquin, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Trina Scherenberg</td>\n",
       "      <td>Special Education Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hamilton, New Jersey</td>\n",
       "      <td>0</td>\n",
       "      <td>Alissa Giambrone</td>\n",
       "      <td>Flight Attendant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Windsor, Colorado</td>\n",
       "      <td>0</td>\n",
       "      <td>Jordan Branch</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Wantagh, New York</td>\n",
       "      <td>0</td>\n",
       "      <td>Kimberly Sherbach</td>\n",
       "      <td>Yoga Instructor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandy, Utah</td>\n",
       "      <td>0</td>\n",
       "      <td>Tandra Steiner</td>\n",
       "      <td>Executive Assistant</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Fort Lauderdale, Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>Tara Eddings</td>\n",
       "      <td>Sport Fishing Enthusiast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake in the Hills, Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>Amanda Goerlitz</td>\n",
       "      <td>Ballet Teacher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carpinteria, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Bo Stanley</td>\n",
       "      <td>Plus-Size Model</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Temecula, California</td>\n",
       "      <td>1</td>\n",
       "      <td>Brittany Fetkin</td>\n",
       "      <td>WWE Diva-in-Training</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brownsville, Kentucky</td>\n",
       "      <td>0</td>\n",
       "      <td>Kara Wilson</td>\n",
       "      <td>High School Soccer Coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Provo, Utah</td>\n",
       "      <td>0</td>\n",
       "      <td>Michelle Davis</td>\n",
       "      <td>Wedding Cake Baker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Scottsdale, Arizona</td>\n",
       "      <td>0</td>\n",
       "      <td>Nicole Meacham</td>\n",
       "      <td>Real Estate Agent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Manhattan Beach, California</td>\n",
       "      <td>0</td>\n",
       "      <td>Reegan Cornwell</td>\n",
       "      <td>Cadaver Tissue Saleswoman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age elimination week  group_dates                           hometown  individual_dates                name                              occupation  roses_from_group_dates  roses_from_individual_dates  season\n",
       "138  22                6            4  Shelby Charter Township, Michigan                 1  Cassandra Ferguson                       Former NBA Dancer                       1                            1      18\n",
       "139  26                5            4              Orland Park, Illinois                 0         Alli Restko                                   Nanny                       0                            0      18\n",
       "140  25                5            3               Litchfield, Illinois                 0      Danielle Ronco                       Psychiatric Nurse                       0                            0      18\n",
       "141  27                5            4                   Conyers, Georgia                 0        Kelly Travis                               Dog Lover                       1                            0      18\n",
       "142  27                4            2           Forty Fort, Pennsylvania                 0         Elise Mosca                     First Grade Teacher                       0                            0      18\n",
       "143  26                4            0                      Austin, Texas                 0      Lauren Solomon                          Music Composer                       0                            0      18\n",
       "144  24                3            2                   Aurora, Illinois                 1      Christy Hansen                       Marketing Manager                       0                            1      18\n",
       "145  25                3            2          Santa Barbara, California                 0               Lucy                              Free Spirit                       0                            0      18\n",
       "146  27                2            0                  Clermont, Florida                 0            Amy Long                     Local News Reporter                       0                            0      18\n",
       "147  27                2            1                     Miami, Florida                 0     Chantel Forrest                         Account Manager                       0                            0      18\n",
       "148  24                2            1               Porto Alegre, Brazil                 1       Victoria Lima                         Legal Assistant                       0                            1      18\n",
       "149  24                1            0                     Tampa, Florida                 0      Alexis Morgado  Communications Director/ NHL  Ice Girl                       0                            0      18\n",
       "150  31                1            0                    Apopka, Florida                 0         Amy Jokinen                       Massage Therapist                       0                            0      18\n",
       "151  25                1            0                     Roanoke, Texas                 0          Ashley Poe                    Grade School Teacher                       0                            0      18\n",
       "152  23                1            0                     Miami, Florida                 0     Christine Llano               Police Support Specialist                       0                            0      18\n",
       "153  23                1            0                 Rockford, Illinois                 0         Kylie Lewis                       Interior Designer                       0                            0      18\n",
       "154  25                1            0         Antelope Acres, California                 0        Lacy Faddoul                      Nursing Home Owner                       0                            0      18\n",
       "155  25                1            0                   Edmond, Oklahoma                 0    Lauren Higginson                     Mineral Coordinator                       0                            0      18\n",
       "156  25                1            0            Wagener, South Carolina                 0        Maggie Gantt                         Personal Banker                       0                            0      18\n",
       "157  26                1            0                 Sutter, California                 0      Valerie Eredia                        Personal Trainer                       0                            0      18\n",
       "158  29           Winner            1               Louisville, Kentucky                 1    Whitney Bischoff                         Fertility Nurse                       0                            1      19\n",
       "159  26        Runner-up            2              Shreveport, Louisiana                 1        Becca Tilley                  Chiropractic Assistant                       1                            1      19\n",
       "160  29                9            4                     Leduc, Alberta                 1    Kaitlyn Bristowe                        Dance Instructor                       3                            1      19\n",
       "161  28                8            2                   Gering, Nebraska                 1          Jade Roper                     Cosmetics Developer                       0                            1      19\n",
       "162  29                7            3                   Arlington, Texas                 0       Carly Waddell                      Cruise Ship Singer                       0                            0      19\n",
       "163  27                7            4              Hollywood, California                 1       Britt Nilsson                                Waitress                       1                            1      19\n",
       "164  24                6            1               Nashville, Tennessee                 1          Megan Bell                          Make-Up Artist                       0                            1      19\n",
       "165  28                6            3              Hudsonville, Michigan                 1          Kelsey Poe                      Guidance Counselor                       0                            0      19\n",
       "166  26                6            0              Great Falls, Virginia                 0    Ashley Iaconetti              Nanny/Freelance Journalist                       0                            0      19\n",
       "167  21                5            3           Maple Valley, Washington                 0   Mackenzie Deonigi                        Dental Assistant                       1                            0      19\n",
       "168  27                5            2              Indianapolis, Indiana                 0    Samantha Steffen                        Fashion Designer                       0                            0      19\n",
       "169  24                4            0                 Brooklyn, New York                 0       Ashley Salter                            Hair Stylist                       0                            0      19\n",
       "170  30                4            3                   Portland, Oregon                 0       Juelia Kinney                             Esthetician                       0                            0      19\n",
       "171  26                4            1                 New York, New York                 0    Nikki Delventhal                  Former NFL Cheerleader                       0                            0      19\n",
       "172  25                4            2                      Howland, Ohio                 0    Jillian Anderson                           News Producer                       0                            0      19\n",
       "173  29                3            2                 Kankakee, Illinois                 0         Amber James                               Bartender                       0                            0      19\n",
       "174  29                3            1                Wellington, Florida                 0       Tracy Darakis                    Fourth Grade Teacher                       0                            0      19\n",
       "175  33                3            1                Algonquin, Illinois                 0   Trina Scherenberg               Special Education Teacher                       0                            0      19\n",
       "176  24                2            1               Hamilton, New Jersey                 0    Alissa Giambrone                        Flight Attendant                       0                            0      19\n",
       "177  24                2            0                  Windsor, Colorado                 0       Jordan Branch                                 Student                       0                            0      19\n",
       "178  28                2            1                  Wantagh, New York                 0   Kimberly Sherbach                         Yoga Instructor                       0                            0      19\n",
       "179  30                2            1                        Sandy, Utah                 0      Tandra Steiner                     Executive Assistant                       0                            0      19\n",
       "180  26                2            1           Fort Lauderdale, Florida                 0        Tara Eddings                Sport Fishing Enthusiast                       0                            0      19\n",
       "181  24                1            0        Lake in the Hills, Illinois                 0     Amanda Goerlitz                          Ballet Teacher                       0                            0      19\n",
       "182  25                1            0            Carpinteria, California                 0          Bo Stanley                         Plus-Size Model                       0                            0      19\n",
       "183  26                1            4               Temecula, California                 1     Brittany Fetkin                    WWE Diva-in-Training                       1                            1      19\n",
       "184  25                1            0              Brownsville, Kentucky                 0         Kara Wilson                High School Soccer Coach                       0                            0      19\n",
       "185  25                1            0                        Provo, Utah                 0      Michelle Davis                      Wedding Cake Baker                       0                            0      19\n",
       "186  31                1            0                Scottsdale, Arizona                 0      Nicole Meacham                       Real Estate Agent                       0                            0      19\n",
       "187  28                1            0        Manhattan Beach, California                 0     Reegan Cornwell               Cadaver Tissue Saleswoman                       0                            0      19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contestantDF.tail(50)  #bachelors are at the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {u'Ali': {u'one-on-one:': True},\n",
       "  'Ashleigh': {u'group:': False},\n",
       "  'Ashley': {u'group:': False},\n",
       "  'Christina': {u'group:': False},\n",
       "  'Corrie': {u'group:': False},\n",
       "  'Elizabeth (NE)': {u'group:': True},\n",
       "  u'Gia': {u'group:': False},\n",
       "  'Jessie': {u'group:': False},\n",
       "  'Kathryn': {u'group:': False},\n",
       "  'Rozlyn': {u'group:': True},\n",
       "  'Valishia': {u'group:': False},\n",
       "  'Vienna': {u'group:': False}},\n",
       " 3: {'Ella': {u'one-on-one:': True}, 'Vienna': {u'one-on-one:': True}},\n",
       " 4: {u'Ali': {u'group:': False},\n",
       "  'Ashleigh': {u'group:': False},\n",
       "  'Corrie': {u'group:': False},\n",
       "  'Ella': {u'two-on-one:': True},\n",
       "  u'Gia': {u'one-on-one:': True},\n",
       "  'Jessie': {u'group:': False},\n",
       "  'Kathryn': {u'two-on-one:': True},\n",
       "  u'Tenley': {u'group:': True},\n",
       "  'Vienna': {u'group:': False}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeklyCompData[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
